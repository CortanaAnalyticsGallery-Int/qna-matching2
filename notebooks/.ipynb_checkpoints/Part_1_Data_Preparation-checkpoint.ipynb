{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Preparation\n",
    "\n",
    "Please make sure you have __notebook__ and __nltk__ Python packages installed in the compute context you choose as kernel. For demonstration purpose, this series of notebooks uses the `local` compute context.\n",
    "\n",
    "**NOTE**: Python 3 kernel doesn't include Azure Machine Learning Workbench functionalities. Please switch the kernel to `local` before continuing further. \n",
    "\n",
    "To install __notebook__ and __nltk__, please uncomment and run the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade notebook\n",
    "# !pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, gzip, requests, warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Sample Data\n",
    "\n",
    "In this example, we have collected a set of Q&A pairs from Stack Overflow site tagged as `JavaScript` questions. The data contains 1,201 original Q&A pairs as well as many duplicate questions, i.e. new questions that Stack Overflow users have linked back to pre-existing Q&A pairs that effectively provide answers to these new questions. The data schema of the original questions (Q), duplicate questions (D), and answers (A) can be found in the following table:\n",
    "\n",
    "| Dataset | Field | Type | Description\n",
    "| ----------|------------|------------|--------\n",
    "| question (Q) | Id | String | The unique question ID (primary key)\n",
    "|  | AnswerId | String | The unique answer ID per question\n",
    "|  | Text0 | String | The raw text data including the question's title and body\n",
    "|  | CreationDate | Timestamp | The timestamp of when the question has been asked\n",
    "| dupes (D) | Id | String | The unique duplication ID (primary key)\n",
    "|  | AnswerId | String | The answer ID associated with the duplication\n",
    "|  | Text0 | String | The raw text data including the duplication's title and body\n",
    "|  | CreationDate | Timestamp | The timestamp of when the duplication has been asked\n",
    "| answers (A) | Id | String | The unique answer ID (primary key)\n",
    "|  | text0 | String | The raw text data of the answer\n",
    "\n",
    "The datasets are compressed and stored in Azure Blob storage as `.tsv.gz` files and this section provides you the code to retreive the data in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load raw data from a .tsv.gz file into Pandas data frame.\n",
    "def read_csv_gz(url, **kwargs):\n",
    "    df = pd.read_csv(gzip.open(requests.get(url, stream=True).raw, mode='rb'), sep='\\t', encoding='utf8', **kwargs)\n",
    "    return df.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# URLs to Original questions, Duplications, and Answers.\n",
    "questions_url = 'https://bostondata.blob.core.windows.net/stackoverflow/orig-q.tsv.gz'\n",
    "dupes_url = 'https://bostondata.blob.core.windows.net/stackoverflow/dup-q.tsv.gz'\n",
    "answers_url = 'https://bostondata.blob.core.windows.net/stackoverflow/ans.tsv.gz'\n",
    "\n",
    "# load datasets.\n",
    "questions = read_csv_gz(questions_url, names=('Id', 'AnswerId', 'Text0', 'CreationDate'))\n",
    "dupes = read_csv_gz(dupes_url, names=('Id', 'AnswerId', 'Text0', 'CreationDate'))\n",
    "answers = read_csv_gz(answers_url, names=('Id', 'Text0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Text Data\n",
    "\n",
    "### Clean up text\n",
    "\n",
    "The raw data is in `HTML` format and needs to be cleaned up for any further analysis. We exclude HTML tags, links and code snippets from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove embedded code chunks, HTML tags and links/URLs.\n",
    "def clean_text(text):\n",
    "    global EMPTY\n",
    "    EMPTY = ''\n",
    "    \n",
    "    if not isinstance(text, str): \n",
    "        return text\n",
    "    text = re.sub('<pre><code>.*?</code></pre>', EMPTY, text)\n",
    "\n",
    "    def replace_link(match):\n",
    "        return EMPTY if re.match('[a-z]+://', match.group(1)) else match.group(1)\n",
    "    \n",
    "    text = re.sub('<a[^>]+>(.*)</a>', replace_link, text)\n",
    "    return re.sub('<[^>]+>', EMPTY, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in (questions, dupes, answers):\n",
    "    df['Text'] = df['Text0'].apply(clean_text).str.lower()\n",
    "    df['NumChars'] = df['Text'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data selection criteria\n",
    "\n",
    "To obtain the high quality datasets for phrase learning and model training, we requires a minimum length of characters in the text field. Different thresholds are considered for original questions, duplications, and answers, respectively. Also, each Q&A pair in our set must have a minimum of 3 additional semantically equivalent duplicate questions linked to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the AnswerIds has at least 3 dupes.\n",
    "def find_answerId(answersC, dupesC, num_dupes):\n",
    "       \n",
    "    countHash = {}\n",
    "    for i in dupesC.AnswerId:\n",
    "        if i not in answersC.index.values:\n",
    "            continue\n",
    "        if i not in countHash.keys():\n",
    "            countHash[i] = 1\n",
    "        else:\n",
    "            countHash[i] += 1\n",
    "            \n",
    "    countHash = {k: v for k, v in countHash.items() if v >= num_dupes}\n",
    "    commonAnswerId = countHash.keys()\n",
    "    \n",
    "    return commonAnswerId\n",
    "\n",
    "# extract data based on the selection criteria.\n",
    "def select_data(questions, dupes, answers):\n",
    "    # exclude the records without any text\n",
    "    questions_nz = questions.query('NumChars > 0')\n",
    "    dupes_nz = dupes.query('NumChars > 0')\n",
    "    answers_nz = answers.query('NumChars > 0')\n",
    "\n",
    "    # get the 10th percentile of text length as the minimum length of characters to consider in the text field\n",
    "    minLenQ = questions_nz.quantile(.1)['NumChars']\n",
    "    minLenD = dupes_nz.quantile(.1)['NumChars']\n",
    "    minLenA = answers_nz.quantile(.1)['NumChars']\n",
    "    \n",
    "    # eliminate records with text less than the minimum length\n",
    "    questionsC = questions.query('NumChars >' + str(int(minLenQ)))\n",
    "    dupesC = dupes.query('NumChars >' + str(minLenD))\n",
    "    answersC = answers.query('NumChars >' + str(minLenA))\n",
    "    \n",
    "    # remove the records in dupesC whose questionId has already existed in questionsC\n",
    "    duplicatedIndex = list(set(questionsC.index).intersection(set(dupesC.index)))\n",
    "    dupesC.drop(duplicatedIndex, inplace=True)\n",
    "    \n",
    "    # make sure Questions 1:1 match with Answers \n",
    "    matches = questionsC.merge(answersC, left_on = 'AnswerId', right_index = True)\n",
    "    questionsC = matches[['AnswerId', 'Text0_x', 'CreationDate', 'Text_x', 'NumChars_x']]\n",
    "    questionsC.columns = ['AnswerId', 'Text0', 'CreationDate', 'Text', 'NumChars']\n",
    "\n",
    "    answersC = matches[['Text0_y', 'Text_y', 'NumChars_y']]\n",
    "    answersC.index = matches['AnswerId']\n",
    "    answersC.columns = ['Text0', 'Text', 'NumChars']\n",
    "    \n",
    "    # find the AnswerIds has at least 3 dupes\n",
    "    commonAnswerId = find_answerId(answersC, dupesC, 3)\n",
    "    \n",
    "    # select the records with those AnswerIds\n",
    "    questionsC = questionsC.loc[questionsC.AnswerId.isin(commonAnswerId)]\n",
    "    dupesC = dupesC.loc[dupesC.AnswerId.isin(commonAnswerId)]\n",
    "    \n",
    "    return questionsC, dupesC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some questions have been linked to multiple AnswerIds. We need to remove the duplicated AnswerIds for those questions.\n",
    "questions = questions.groupby(questions.index).first()\n",
    "dupes = dupes.groupby(dupes.index).first()\n",
    "\n",
    "# execute the data selection function on questions, dupes and answers.\n",
    "questionsC, dupesC = select_data(questions, dupes, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training and Test datasets\n",
    "\n",
    "In this example, we retain original question and 75% of the duplicate questions for training, and hold-out the most recently posted 25% of duplicate questions as test data. The training and test data are splitted by `CreationDate`.\n",
    "\n",
    "- training set = Original questions + 75% of oldest Duplications per original question\n",
    "- test set = remaining 25% of Duplications per original question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split Original questions and their Duplications into training and test sets.\n",
    "def split_data(questions, dupes, frac):\n",
    "    trainQ = questions\n",
    "    testQ = pd.DataFrame(columns = dupes.columns.values) # create an empty data frame\n",
    "\n",
    "    for answerId in np.unique(dupes.AnswerId):\n",
    "        df = dupes.query('AnswerId == ' + str(answerId))\n",
    "        totalCount = len(df)\n",
    "        splitPoint = int(totalCount * frac)\n",
    "        dfSort = df.sort_values(by = ['CreationDate'])\n",
    "        trainQ = trainQ.append(dfSort.head(splitPoint)) # oldest N percent of duplications\n",
    "        testQ = testQ.append(dfSort.tail(totalCount - splitPoint))\n",
    "\n",
    "    # convert data type to int\n",
    "    testQ[[\"AnswerId\", \"NumChars\"]] = testQ[[\"AnswerId\", \"NumChars\"]].astype(int) \n",
    "    # rename the index \n",
    "    testQ.index.rename(\"Id\", inplace=True)\n",
    "    \n",
    "    return trainQ, testQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainQ, testQ = split_data(questionsC, dupesC, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainQ.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Subsets with Sufficient Training Questions per Answer Class\n",
    "\n",
    "In our past experiments, we notice that some Q&A pairs only link to a small number of duplicate questions. This means those answer classes may contain insufficient amount of examples for model training. We examine the effect of the number of duplicate questions available for training for each Q&A pair. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Azure/MachineLearningSamples-QnAMatching/master/Image/training_size.PNG?token=APoO9rnKXamwVdXu8luA_Dd28UUBncwrks5ZwtRowA%3D%3D\">\n",
    "\n",
    "The above Figure shows results for questions relative to the number of training examples available for the correct Q&A pair that should be returned. Most of our Q&A pairs (857 out of 1201) have 5 or fewer known duplicate questions available for training.  Performance on these questions is relatively weak, with the correct Q&A pair landing in the top 10 results less than 40% of the time. However, when greater numbers of duplicate questions are available for training, performance improves dramatically; when Q&A pairs have 50 or more duplicate questions available for training, the classification model places these pairs in the top 10 of the retrieved results 98% of the time when they correctly match the query. \n",
    "\n",
    "With the above study, we only consider the answer classes that have more than 13 training questions (original and duplicate questions) in this notebook. This reduces the entire dataset to 5,153 training questions, 1,735 test questions, and 103 unique answer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countPerAns = pd.DataFrame({\"NumTrain\" : trainQ.groupby(\"AnswerId\").size()})\n",
    "trainQwithCount = trainQ.merge(countPerAns, left_on=\"AnswerId\", right_index=True)\n",
    "testQwithCount = testQ.merge(countPerAns, left_on=\"AnswerId\", right_index=True)\n",
    "\n",
    "# for each Answer class, we request more than 13 training questions.\n",
    "trainQ = trainQwithCount[trainQwithCount[\"NumTrain\"] > 13]\n",
    "testQ = testQwithCount[testQwithCount[\"NumTrain\"] > 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"# of training examples: \" + str(len(trainQ)))\n",
    "print(\"# of testing examples: \" + str(len(testQ)) + \"\\n\")\n",
    "print(\"A quick glance of the training data: \\n\")\n",
    "trainQ[[\"AnswerId\", \"Text\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs to a Share Directory in the Workbench\n",
    "\n",
    "Azure Machine Learning Workbench provides a flexible way of saving intermediate files. `os.environ.get('AZUREML_NATIVE_SHARE_DIRECTORY')` retrieves a share directory where the files are stored. Those files can be accessed from other notebooks or Python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workfolder = os.environ.get('AZUREML_NATIVE_SHARE_DIRECTORY')\n",
    "trainQ.to_csv(os.path.join(workfolder, 'trainQ_part1'), sep='\\t', header=True, index=True, index_label='Id')\n",
    "testQ.to_csv(os.path.join(workfolder, 'testQ_part1'), sep='\\t', header=True, index=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qna-matching2 local",
   "language": "python",
   "name": "qna-matching2_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
